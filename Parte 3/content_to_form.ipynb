{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content to Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "from nltk.corpus import wordnet as wn\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pandas.read_excel('res/content-to-form.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = file.columns\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for w in ['just', 'will']:\n",
    "    stopwords.remove(w)\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "defs = []\n",
    "for i in range(1, len(columns)):\n",
    "    column = [d for d in file[columns[i]].values if d==d]\n",
    "    definition = set()\n",
    "    for i in range(len(column)):\n",
    "        definition.update([stemmer.stem(w.lower()) for w in tokenizer.tokenize(column[i]) if not w.lower() in stopwords])\n",
    "    defs.append(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(a, b):\n",
    "    return len(a & b) / min(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_set(synset):\n",
    "    bag = set()\n",
    "    bag.update([stemmer.stem(w.lower()) for w in tokenizer.tokenize(synset.definition()) if not w.lower() in stopwords])\n",
    "    for example in synset.examples():\n",
    "        bag.update([stemmer.stem(w.lower()) for w in tokenizer.tokenize(example) if not w.lower() in stopwords])\n",
    "    for lemma in synset.lemmas():\n",
    "        bag.update([stemmer.stem(w.lower()) for w in tokenizer.tokenize(lemma.name().replace('_', ' ')) if not w.lower() in stopwords])\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_to_form(definition):\n",
    "    h = [] # heap\n",
    "    i = 0 # not improving steps\n",
    "    max_steps = 10000 # maximum not improving steps\n",
    "    best_syn = wn.synset('entity.n.01')\n",
    "    max_score = sim(definition, syn_set(best_syn))\n",
    "    heappush(h, (-max_score, best_syn))\n",
    "\n",
    "    while i < max_steps and h:\n",
    "        (_, syn) = heappop(h)\n",
    "        for hypo in syn.hyponyms():\n",
    "            score = sim(definition, syn_set(hypo))\n",
    "            heappush(h, (-score, hypo))\n",
    "            if(score > max_score):\n",
    "                best_syn = hypo\n",
    "                max_score = score\n",
    "                i = -1\n",
    "        i += 1\n",
    "\n",
    "    return (best_syn, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('justice.n.01'), 0.75)\n",
      "(Synset('hard_times.n.01'), 1.0)\n",
      "(Synset('desire.n.03'), 1.0)\n",
      "(Synset('regulation.n.03'), 0.75)\n",
      "(Synset('animal_order.n.01'), 1.0)\n",
      "(Synset('heater.n.01'), 0.75)\n",
      "(Synset('landing.n.02'), 0.8571428571428571)\n",
      "(Synset('slice.n.05'), 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "for definition in defs:\n",
    "    print(content_to_form(definition))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
